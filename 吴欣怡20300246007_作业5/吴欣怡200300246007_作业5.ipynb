{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11283896,"sourceType":"datasetVersion","datasetId":7055006},{"sourceId":11286574,"sourceType":"datasetVersion","datasetId":7056890}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi\n!nvcc --version","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\n# import torchvision.transforms as transforms\nimport torchsummary\nfrom tqdm import tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1) GPU？\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using {device} device\")\n\n# <1> 数据预处理\ntransform = torchvision.transforms.Compose([\n        torchvision.transforms.Resize((224, 224)),\n        torchvision.transforms.ToTensor()  ])\n\n# <2> 加载MNIST数据集\ndataset = torchvision.datasets.ImageFolder(root=\"/kaggle/input/imgnet-10/ImageNet-10\", transform=transform)\ntrain_size = int(0.8 * len(dataset))  # 训练集占80%，1,300张*0.8=1040张\ntest_size = len(dataset) - train_size # 测试集占20%，1,300张-1040张=260张\ntorch.manual_seed(42)  # 为了保证每次划分的数据集一致\ntrainset, testset = torch.utils.data.random_split(dataset, [train_size, test_size])\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False, num_workers=4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# <3> 定义AlexNet模型\nalexnet = nn.Sequential(\n    nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=1),  nn.ReLU(),\n    nn.MaxPool2d(kernel_size=3, stride=2),\n    nn.Conv2d(96, 256, kernel_size=5, padding=2),           nn.ReLU(),\n    nn.MaxPool2d(kernel_size=3, stride=2),\n    nn.Conv2d(256, 384, kernel_size=3, padding=1),          nn.ReLU(),\n    nn.Conv2d(384, 384, kernel_size=3, padding=1),          nn.ReLU(),\n    nn.Conv2d(384, 256, kernel_size=3, padding=1),          nn.ReLU(),\n    nn.MaxPool2d(kernel_size=3, stride=2),\n    nn.Flatten(),\n    nn.Linear(6400, 4096),                                  nn.ReLU(),\n    nn.Dropout(p=0.5),  # 防止过拟合，丢弃概率为50%\n    nn.Linear(4096, 4096),                                  nn.ReLU(),\n    nn.Dropout(p=0.5),\n    nn.Linear(4096, 10),\n).to(device)  # 2) 将模型加载到GPU上\n\n# torchsummary\ntorchsummary.summary(alexnet, (3, 224, 224))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# <4> 损失函数\ncriterion = nn.CrossEntropyLoss()\n\n# <5> 优化器\noptimizer = optim.Adam(alexnet.parameters(), lr=0.0001)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# <6> 自定义计算准确率函数\ndef test(model, testloader):\n    # <6-1> 进入评估模式\n    model.eval()\n\n    # <6-2> 计算输出\n    correct = total = 0\n    with torch.no_grad():   # 关闭梯度计算\n        # 从测试集中一批一批地取数据, 每批64个, 一共取260/64=4次+1次\n        for images, labels in testloader:\n\n            # 4) 将测试数据加载到GPU上\n            images, labels = images.to(device), labels.to(device)\n\n            # 计算预测值\n            outputs = model(images)\n\n            # <6-3> 计算准确率\n            # 按行(=1)取最大值，返回最大值、最大值的索引(预测结果)\n            _, predicted = torch.max(outputs.data, 1)\n\n            # 预测值与真实值比较后, 再求和\n            correct += (predicted == labels).sum().item()\n            # 测试集总数\n            total += labels.size(0)\n\n    # 准确率\n    accuracy = correct / total\n\n    # 返回：准确率\n    return accuracy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# <7> 训练模型\n# 初始化训练过程中的指标：训练精度、测试精度、损失，用于绘图\ntrain_acc_history, test_acc_history, loss_history = [], [], []\n\nfor epoch in tqdm(range(10)):  # 训练10个epoch\n    alexnet.train()\n    epoch_loss = 0.0        # 每epoch的损失\n    running_loss = 0.0      # 每64批次batch的损失\n\n    # 从0开始计数，每次取一个batch，一共取1040/64=16.25次\n    for i, data in enumerate(trainloader, 0):\n        X_train, y_train = data\n\n        # 3) 将训练数据加载到GPU上\n        X_train, y_train = X_train.to(device), y_train.to(device)\n\n        optimizer.zero_grad()\n        outputs = alexnet(X_train)\n        loss = criterion(outputs, y_train)\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        running_loss += loss.item()\n\n        # 每100个batch打印一次损失\n        if i % 100 == 99:\n            print(f\"[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.8f}\")\n            running_loss = 0.0\n\n    # 更新绘图指标\n    train_acc_history.append(test(alexnet, trainloader))\n    test_acc_history.append(test(alexnet, testloader))\n    loss_history.append(epoch_loss / len(trainloader))\n    print(f\"Epoch {epoch + 1} loss: {epoch_loss / len(trainloader):.8f}, train accuracy: {train_acc_history[-1]:.3%}, test accuracy: {test_acc_history[-1]:.3%}\")\n\n# 清空CUDA缓存\ntorch.cuda.empty_cache()\n\n# 打印CUDA内存使用情况\nprint(f\"CUDA memory allocated: {torch.cuda.memory_allocated(device) / 1024**2:.0f} MB\")\n\nprint(\"Finished Training\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# <8> 绘制训练过程中的指标\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams  # 设置全局参数，为了设置中文字体\n\n\n# 定义绘制函数\ndef draw_plot(train_acc_history, test_acc_history, loss_history):\n    plt.figure()\n    plt.plot(train_acc_history, label=\"train accuracy\")\n    plt.plot(test_acc_history, label=\"test accuracy\")\n    plt.plot(loss_history, label=\"loss\")\n    plt.legend()  # 显示图例\n    plt.xlabel(\"迭代次数\")\n    plt.show()\n\n\ndraw_plot(train_acc_history, test_acc_history, loss_history)\nprint(f\"最终训练精度: {train_acc_history[-1]:.2%}\")\nprint(f\"最终测试精度: {test_acc_history[-1]:.2%}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport torch\nimport torchvision.transforms as transforms\nimport torchvision.models as models\n\n# 打开图像文件\nimage_path = \"/kaggle/input/predict/chicken.jpg\"\nimage = Image.open(image_path)\ndisplay(image)\n\n# 图像预处理\nimage = transform(image)\nimage = image.unsqueeze(0)  # Add batch dimension\n\n# 设置评估模式\nalexnet.eval()\n\n# 预测\nwith torch.no_grad():\n    output = alexnet(image.to(device))\n\n# 预测结果\n_, predicted = torch.max(output, 1)\nprint(f\"预测类别: {predicted.item()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# <3> 定义ResNet34模型\nresnet34 = models.resnet34()  # 加载预训练的ResNet34模型\n# 修改最后的全连接层以适应10个类别\nnum_ftrs = resnet34.fc.in_features\nresnet34.fc = nn.Linear(num_ftrs, 10)\n# 将模型移动到GPU\nresnet34 = resnet34.to(device)  # 2) 将模型加载到GPU上\n\n# torchsummary\ntorchsummary.summary(resnet34, (3, 224, 224))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# <4> 损失函数\ncriterion = nn.CrossEntropyLoss()\n\n# <5> 优化器\noptimizer = optim.Adam(resnet34.parameters(), lr=0.0001)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# <7> 训练模型\n# 初始化训练过程中的指标：训练精度、测试精度、损失，用于绘图\ntrain_acc_history, test_acc_history, loss_history = [], [], []\n\nprint(\"Total number of images for training: \", len(trainset))\n\nfor epoch in range(10):  # 训练10个epoch\n    resnet34.train()\n    epoch_loss = 0.0  # 每epoch的损失\n    running_loss = 0.0  # 每64批次batch的损失\n\n    # 从0开始计数，每次取一个batch，一共取10400/16=650次\n    for i, data in enumerate(trainloader, 0):\n        X_train, y_train = data\n\n        # 3) 将训练数据加载到GPU上\n        X_train, y_train = X_train.to(device), y_train.to(device)\n\n        optimizer.zero_grad()\n        outputs = resnet34(X_train)\n        loss = criterion(outputs, y_train)\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        running_loss += loss.item()\n\n        # 每100个batch打印一次损失\n        if i % 100 == 99:\n            print(f\"[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.8f}\")\n            running_loss = 0.0\n\n    # 更新绘图指标\n    train_acc_history.append(test(resnet34, trainloader))\n    test_acc_history.append(test(resnet34, testloader))\n    loss_history.append(epoch_loss / len(trainloader))\n    print(\n        f\"Epoch {epoch + 1} loss: {epoch_loss / len(trainloader):.8f}, train accuracy: {train_acc_history[-1]:.3%}, test accuracy: {test_acc_history[-1]:.3%}\"\n    )\n\n# 清空CUDA缓存\ntorch.cuda.empty_cache()\n\n# 打印CUDA内存使用情况\nprint(f\"CUDA memory allocated: {torch.cuda.memory_allocated(device) / 1024**2:.0f} MB\")\n\nprint(\"Finished Training\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}